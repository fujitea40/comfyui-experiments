{
  "2": {
    "inputs": {
      "image": "ComfyUI_00054_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "20": {
    "inputs": {
      "model_name": "GroundingDINO_SwinB (938MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  },
  "21": {
    "inputs": {
      "model_name": "sam_vit_l (1.25GB)"
    },
    "class_type": "SAMModelLoader (segment anything)",
    "_meta": {
      "title": "SAMModelLoader (segment anything)"
    }
  },
  "22": {
    "inputs": {
      "prompt": "face, eyes, mouth",
      "threshold": 0.35,
      "sam_model": [
        "21",
        0
      ],
      "grounding_dino_model": [
        "20",
        0
      ],
      "image": [
        "2",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "24": {
    "inputs": {
      "mask": [
        "22",
        1
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "25": {
    "inputs": {
      "images": [
        "24",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "29": {
    "inputs": {
      "grow_mask_by": 3,
      "pixels": [
        "2",
        0
      ],
      "vae": [
        "32",
        2
      ],
      "mask": [
        "2",
        1
      ]
    },
    "class_type": "VAEEncodeForInpaint",
    "_meta": {
      "title": "VAE Encode (for Inpainting)"
    }
  },
  "31": {
    "inputs": {
      "seed": 152848092228762,
      "steps": [
        "43",
        3
      ],
      "cfg": [
        "43",
        1
      ],
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": [
        "43",
        2
      ],
      "model": [
        "32",
        0
      ],
      "positive": [
        "33",
        0
      ],
      "negative": [
        "34",
        0
      ],
      "latent_image": [
        "40",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "32": {
    "inputs": {
      "ckpt_name": "meinamix_v12Final.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "33": {
    "inputs": {
      "text": [
        "43",
        0
      ],
      "clip": [
        "32",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "34": {
    "inputs": {
      "text": "different hairstyle, different face shape,\ndifferent eye color, asymmetrical face,\nstrong lighting change,\ndeformed face\n",
      "clip": [
        "32",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "35": {
    "inputs": {
      "samples": [
        "31",
        0
      ],
      "vae": [
        "32",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "36": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "35",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "40": {
    "inputs": {
      "samples": [
        "29",
        0
      ],
      "mask": [
        "22",
        1
      ]
    },
    "class_type": "SetLatentNoiseMask",
    "_meta": {
      "title": "Set Latent Noise Mask"
    }
  },
  "43": {
    "inputs": {
      "common_prompt": "1girl, anime style, clean lineart, consistent proportions, high quality, character illustration",
      "expression": "big_smile_closed_eyes"
    },
    "class_type": "ExpressionPresetNode",
    "_meta": {
      "title": "Expression Preset Selector"
    }
  }
}